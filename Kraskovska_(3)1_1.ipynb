{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторна робота 3. Побудова автокодувальника\n",
        "студентки групи ФІТ 4-4\n",
        "Красковської Анастасії Олександрівни\n",
        "\n",
        "**Завдання 1**\n",
        "\n",
        "1.\tРозробити звичайний автокодувальник  для датасету рукописних цифр MNIST на основі багатошарової нейронної мережі."
      ],
      "metadata": {
        "id": "PN9WxtaECEK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrTTdnLByOm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Завантаження датасету MNIST\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Нормалізація даних\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Переведення зображень у вектори (приведення до одномірної форми)\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Функція для створення моделі\n",
        "def build_autoencoder(input_dim, encoding_dim):\n",
        "    input_img = tf.keras.layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # Encoder\n",
        "    encoded = tf.keras.layers.Dense(128, activation='relu')(input_img)\n",
        "    encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "    # Decoder\n",
        "    decoded = tf.keras.layers.Dense(128, activation='relu')(encoded)\n",
        "    decoded = tf.keras.layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "    # Combine Encoder and Decoder layers\n",
        "    autoencoder = tf.keras.models.Model(input_img, decoded)\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# Задаємо розмірність вхідних та закодованих зображень\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 32  # Кількість нейронів у прихованому шарі\n",
        "\n",
        "# Побудова моделі\n",
        "autoencoder = build_autoencoder(input_dim, encoding_dim)\n",
        "autoencoder.summary()\n",
        "\n",
        "# Компіляція моделі\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Навчання моделі\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                          epochs=20,\n",
        "                          batch_size=256,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(x_test, x_test))\n",
        "\n",
        "# Візуалізація функції втрат\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Результати реконструкції\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Відображення оригінальних та відтворених зображень\n",
        "n = 10  # Кількість зображень для відображення\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Оригінальне зображення\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Відтворене зображення\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title('Reconstructed')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Вибір 100 випадкових зображень\n",
        "indices = np.random.randint(0, x_train.shape[0], 100)\n",
        "images = x_train[indices]\n",
        "\n",
        "# Виведення випадкових зображень\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(len(indices)):\n",
        "    plt.subplot(10, 10, i + 1)\n",
        "    plt.imshow(images[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1PqmMtlOCQ05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновок:** У рамках першого завдання я розробила звичайний автокодувальник для датасету рукописних цифр MNIST, використовуючи багатошарову нейронну мережу. Модель складалася з вхідного шару, двох прихованих шарів (енкодер і декодер) та вихідного шару.\n",
        "\n",
        "Після завершення навчання моделі, я створила графік функції втрат для тренувального та валідаційного наборів даних. За аналізом цього графіка стало очевидним, що функція втрат систематично зменшувалася з кожною епохою, що вказує на успішність навчання моделі.\n",
        "\n",
        "Крім того, я порівняла оригінальні та відтворені зображення для оцінки якості автокодування. Ці порівняння показали, що автокодувальник ефективно відтворює рукописні цифри з високою точністю, що свідчить про вдалий результат розробленої моделі."
      ],
      "metadata": {
        "id": "473q1blJCXlo"
      }
    }
  ]
}